experiment_series: RL_DLDLM
experiment_id: dldlm_medium_emp
experiments_directory_path: $DLDLM/experiments/

random_seed: 2307
mixed_precision: true

dldlm:
  model:
    pretrained: &pretrained $DLDLM/resources/models/dldlm-medium
    additional_kwargs:
      rl_weight: 0.5
      detach_posterior: true
  reinforce:
    gamma: 0.9
    reward_weights:
      - 0.9
      - 0.1
  tokeniser:
    pretrained: *pretrained

optimizer:
  kwargs:
    lr: &lr 3.125e-5
  n_epochs: 1
  max_gradient_norm: 1.0

lr_scheduler:
  lr_start: *lr
  lr_stop: 0.0
  warmup: 0.002

data:
  csv_file_path: $DLDLM/resources/data/dialogue_corpus/corpus.csv
  splits:
    - train
  mini_batch_size: 1
  in_mem: 4
  n_workers: 4

log_level: DEBUG
log_file: true
